{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at mask predictions\n",
    "\n",
    "Running validation data through saved model to look at masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../src')\n",
    "from UNet2D import UNet2D\n",
    "from UNetMultiTask import UNetMultiTask\n",
    "from datasets import MycetomaDataset\n",
    "from metrics import batch_dice_coeff, bce_dice_loss, dice_coefficient\n",
    "from postprocessing import threshold_mask, post_process_binary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = np.array([os.path.relpath(i, DATA_DIR).split('.')[0] for i in glob.glob(f'{DATA_DIR}/corrected_training_dataset/**/*.jpg')])\n",
    "val_paths = np.array([os.path.relpath(i, DATA_DIR).split('.')[0] for i in glob.glob(f'{DATA_DIR}/corrected_validation_dataset/**/*.jpg')])\n",
    "\n",
    "problem_val_paths = np.array(['corrected_validation_dataset/FM/FM10_1'])\n",
    "val_paths = np.setdiff1d(val_paths, problem_val_paths)\n",
    "\n",
    "print(f\"Train length: {len(train_paths)}\")\n",
    "print(f\"Val length: {len(val_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MycetomaDataset(train_paths, DATA_DIR)\n",
    "val_dataset = MycetomaDataset(val_paths, DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an image, along with prediction and ground truth\n",
    "def plot_image(im, pred, gt):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "    ax[0].imshow(im)\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(pred)\n",
    "    ax[1].set_title('prediction')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    ax[2].imshow(gt)\n",
    "    ax[2].set_title('GT')\n",
    "    ax[2].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and load model save\n",
    "model = UNetMultiTask(3, 1, 8)\n",
    "state_dict = torch.load('../model_saves/more_dropout_jitter_bs_32_lr_1e-3_lw_0.2_best_model.pth', map_location=torch.device(device))\n",
    "\n",
    "# Sometimes, the model dictionary keys contain 'module.' prefix which we don't want\n",
    "remove_prefix = True\n",
    "\n",
    "if remove_prefix:\n",
    "    remove_prefix = 'module.'\n",
    "    state_dict = {k[len(remove_prefix):] if k.startswith(remove_prefix) else k: v for k, v in state_dict.items()}\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put validation data through, plotting image, postproc prediction, ground truth each time\n",
    "from tqdm import tqdm\n",
    "\n",
    "threshold = 0.5\n",
    "dice_coeff = 0.0\n",
    "post_dice_coeff = 0.0\n",
    "gts = []\n",
    "preds = []\n",
    "n = 0\n",
    "\n",
    "# Perform loop without computing gradients\n",
    "with torch.no_grad():\n",
    "    for idx, (inputs, targets, labels) in enumerate(val_loader):\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs, class_out = model(inputs)\n",
    "\n",
    "        dice_coeff += batch_dice_coeff(outputs>threshold, targets).detach().cpu().numpy()\n",
    "        n += 1\n",
    "\n",
    "        im = inputs[0].detach().cpu().permute(1,2,0).numpy()\n",
    "        pred = threshold_mask(outputs[0][0].detach().cpu().numpy())\n",
    "        gt = targets[0][0].detach().cpu().numpy()\n",
    "\n",
    "        #plot_image(im, pred, gt)\n",
    "        dice = dice_coefficient(torch.from_numpy(pred).float(), torch.from_numpy(gt).float())\n",
    "\n",
    "        # Post-process mask\n",
    "        post_proc_mask = np.clip(post_process_binary_mask(pred, threshold_fraction=0.05), 0, 1)\n",
    "\n",
    "        post_proc_dice = dice_coefficient(torch.from_numpy(post_proc_mask).float(), torch.from_numpy(gt).float())\n",
    "\n",
    "        post_dice_coeff += post_proc_dice\n",
    "\n",
    "        gts.append(labels.item())\n",
    "        preds.append(class_out.squeeze().item())\n",
    "        \n",
    "        # Plot prediction before and after processing\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "        ax[0].imshow(im)\n",
    "        ax[0].set_title('Image')\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].imshow(post_proc_mask)\n",
    "        ax[1].set_title('Post-Proc Mask')\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        ax[2].imshow(gt)\n",
    "        ax[2].set_title('GT')\n",
    "        ax[2].axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"Classification prediction: {class_out.squeeze().item()}, GT: {labels.item()}\")\n",
    "        print(f\"Dice score before postproc: {dice} vs after: {post_proc_dice}\")\n",
    "\n",
    "pre_proc_dice_av = dice_coeff/n\n",
    "post_proc_dice_av = post_dice_coeff/n\n",
    "print(\"Av. dice score before preproc: \", pre_proc_dice_av, \"vs post: \", post_proc_dice_av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_binary = [1 if pred > 0.5 else 0 for pred in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import accuracy\n",
    "accuracy(torch.tensor(preds), torch.tensor(gts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(gts, preds_binary)\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "#cm_normalised = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_displayed = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Fungal\", \"Bacterial\"])\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm_displayed.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "#plt.savefig('cm_multitask_firstgo.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mycetoma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
